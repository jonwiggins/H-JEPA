# Quick Validation Test Configuration
# Purpose: Verify all recent changes (Flash Attention, TensorBoard, bug fixes)
# Duration: ~1-2 hours on M1 Max
# Dataset: CIFAR-10 (quick to download and train)

experiment:
  name: validation_test_flash_attention
  seed: 42
  output_dir: results/validation_test
  save_frequency: 5
  eval_frequency: 5

model:
  encoder_type: vit_base_patch16_224
  embed_dim: 768
  num_hierarchies: 3
  use_rope: true              # ✓ Enable RoPE
  rope_theta: 10000.0
  use_flash_attention: true   # ✓ Enable Flash Attention (NEW!)
  use_gradient_checkpointing: false
  ema:
    momentum: 0.996
    momentum_end: 1.0
    momentum_warmup_epochs: 2
  predictor:
    depth: 6
    num_heads: 6
    mlp_ratio: 4.0
    qkv_bias: true
    dropout: 0.0

data:
  use_multi_dataset: false
  dataset: cifar10
  data_path: ./data
  image_size: 224
  batch_size: 32              # Small batch for M1 Max
  num_workers: 4
  transforms:
    crop_scale:
      - 0.8
      - 1.0
    horizontal_flip: true
    color_jitter: 0.1

training:
  epochs: 15                  # Short run for validation
  warmup_epochs: 2
  optimizer: adamw
  lr: 0.001
  min_lr: 1.0e-6
  weight_decay: 0.04
  betas:
    - 0.9
    - 0.95
  lr_schedule: cosine
  min_lr_ratio: 0.01
  warmup_lr_ratio: 0.001
  use_amp: true               # Mixed precision

masking:
  num_target_masks: 4
  mask_scale:
    - 0.15
    - 0.2
  aspect_ratio:
    - 0.75
    - 1.5
  num_context_masks: 1

loss:
  type: smoothl1
  hierarchy_weights:
    - 1.0
    - 0.7
    - 0.5
  use_vicreg: false

logging:
  experiment_name: validation_test_flash_attention
  log_dir: results/validation_test/logs
  use_wandb: false             # Disable W&B for quick test
  use_tensorboard: true        # ✓ Enable TensorBoard (with enhancements!)
  log_frequency: 10            # Log every 10 batches
  log_images: true
  log_attention: true
  log_gradients: true
  log_dataset_distribution: false

checkpoint:
  checkpoint_dir: results/validation_test/checkpoints
  save_frequency: 1            # Save every epoch for exploration!
  save_best: true
  metric: val_loss
  mode: min
  keep_last_k: 15              # Keep all epochs for this validation run

device: mps                    # Apple Silicon
