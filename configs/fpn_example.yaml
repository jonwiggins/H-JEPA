# Example configuration for H-JEPA with Feature Pyramid Networks (FPN)
# This demonstrates how to use FPN for improved multi-scale feature learning

# Model architecture settings
model:
  # Vision Transformer backbone
  encoder_type: "vit_base_patch16_224"

  # Embedding dimension
  embed_dim: 768

  # Number of hierarchical levels
  num_hierarchies: 3

  # Predictor configuration
  predictor:
    depth: 6
    num_heads: 12
    mlp_ratio: 4.0

  # EMA (Exponential Moving Average) settings for target encoder
  ema:
    momentum: 0.996
    momentum_end: 1.0
    momentum_warmup_epochs: 30

  # Feature Pyramid Network (FPN) settings - ENABLED
  fpn:
    # Enable FPN for multi-scale feature learning
    use_fpn: true

    # Feature dimension for FPN (use 512 for reduced computation)
    # Set to null to use the same dimension as embed_dim (768)
    feature_dim: 512

    # Feature fusion method
    # 'add': element-wise addition (faster, less parameters)
    # 'concat': concatenation with 1x1 conv (more expressive)
    fusion_method: "add"

# Dataset and data loading
data:
  dataset: "imagenet"
  data_path: "/path/to/dataset"
  image_size: 224
  batch_size: 128
  num_workers: 8
  pin_memory: true

  augmentation:
    color_jitter: 0.4
    horizontal_flip: true
    random_crop: true

# Multi-block masking strategy
masking:
  num_masks: 4
  mask_scale: [0.15, 0.2]
  aspect_ratio: [0.75, 1.5]
  num_context_masks: 1
  context_scale: [0.85, 1.0]

# Training hyperparameters
training:
  epochs: 300
  warmup_epochs: 40
  lr: 1.5e-4
  min_lr: 1.0e-6
  weight_decay: 0.05
  optimizer: "adamw"
  betas: [0.9, 0.95]
  lr_schedule: "cosine"
  clip_grad: 3.0
  use_amp: true
  accumulation_steps: 1

# Loss function settings
loss:
  type: "mse"
  # With FPN, you may want to adjust hierarchy weights
  # as FPN improves feature quality at all scales
  hierarchy_weights: [1.0, 0.7, 0.5]
  normalize_embeddings: false

# Checkpointing and logging
checkpoint:
  save_frequency: 10
  keep_best_n: 3
  checkpoint_dir: "results/checkpoints_fpn"
  resume: null

# Logging configuration
logging:
  experiment_name: "hjepa_fpn_add"
  log_dir: "results/logs_fpn"
  log_frequency: 100

  wandb:
    enabled: true
    project: "h-jepa"
    entity: null
    tags: ["fpn", "vit-base", "multi-scale"]

  tensorboard:
    enabled: true

# Distributed training settings
distributed:
  enabled: false
  backend: "nccl"
  world_size: 1

# Evaluation settings
evaluation:
  eval_frequency: 10
  linear_probe:
    enabled: false
    dataset: "imagenet"
    batch_size: 256
    epochs: 90
    lr: 0.1

# Reproducibility
seed: 42

# Device settings
device: "cuda"
