# Default configuration for H-JEPA training

# Model architecture settings
model:
  # Vision Transformer backbone (options: vit_small_patch16_224, vit_base_patch16_224, vit_large_patch16_224)
  encoder_type: "vit_base_patch16_224"

  # Embedding dimension
  embed_dim: 768

  # Number of hierarchical levels
  num_hierarchies: 3

  # Predictor configuration
  predictor:
    depth: 6
    num_heads: 12
    mlp_ratio: 4.0

  # EMA (Exponential Moving Average) settings for target encoder
  ema:
    momentum: 0.996
    momentum_end: 1.0
    momentum_warmup_epochs: 30

  # Rotary Position Embeddings (RoPE) settings
  # RoPE provides better position encoding than absolute embeddings
  # Used in V-JEPA 2 and modern ViTs for improved resolution generalization
  rope:
    # Enable RoPE (default: false for backward compatibility)
    use_rope: false

    # Base frequency for rotation (default: 10000.0 as in original RoPE paper)
    # Higher values = slower decay of position information
    # Lower values = faster decay, better for shorter sequences
    theta: 10000.0

  # Performance optimizations
  use_flash_attention: true  # Enable Flash Attention for 2-5x speedup (requires PyTorch 2.0+)

  # Feature Pyramid Network (FPN) settings
  fpn:
    # Enable FPN for multi-scale feature learning
    use_fpn: false

    # Feature dimension for FPN (null means use embed_dim)
    feature_dim: null

    # Feature fusion method ('add' or 'concat')
    # 'add': element-wise addition of lateral and top-down features
    # 'concat': concatenation followed by 1x1 conv
    fusion_method: "add"

# Dataset and data loading
data:
  # Dataset name (imagenet, cifar10, custom)
  dataset: "imagenet"

  # Data directory
  data_path: "/path/to/dataset"

  # Image size
  image_size: 224

  # Batch size per GPU
  batch_size: 128

  # Number of data loading workers
  num_workers: 8

  # Pin memory for faster data transfer
  pin_memory: true

  # Data augmentation settings
  augmentation:
    color_jitter: 0.4
    horizontal_flip: true
    random_crop: true

# Multi-block masking strategy
masking:
  # Number of target blocks to predict
  num_masks: 4

  # Mask scale range (as fraction of image)
  mask_scale: [0.15, 0.2]

  # Aspect ratio range for masks
  aspect_ratio: [0.75, 1.5]

  # Number of context blocks
  num_context_masks: 1

  # Context mask scale
  context_scale: [0.85, 1.0]

# Training hyperparameters
training:
  # Total number of epochs
  epochs: 300

  # Warmup epochs
  warmup_epochs: 40

  # Base learning rate (scales with batch size)
  lr: 1.5e-4

  # Minimum learning rate
  min_lr: 1.0e-6

  # Weight decay
  weight_decay: 0.05

  # Optimizer (adamw, sgd)
  optimizer: "adamw"

  # Betas for AdamW
  betas: [0.9, 0.95]

  # Learning rate schedule (cosine, linear)
  lr_schedule: "cosine"

  # Gradient clipping
  clip_grad: 3.0

  # Mixed precision training
  use_amp: true

  # Gradient accumulation steps
  accumulation_steps: 1

  # Gradient checkpointing for memory-efficient training
  # Trades computation for memory by recomputing activations during backward pass
  # Recommended for large models or when training with limited GPU memory
  # Memory savings: ~30-50% depending on model depth
  # Performance impact: ~20-30% slower training due to recomputation
  use_gradient_checkpointing: false

# Loss function settings
loss:
  # Loss type (mse, smoothl1, huber)
  type: "mse"

  # Hierarchical loss weights (one per hierarchy level)
  hierarchy_weights: [1.0, 0.5, 0.25]

  # Whether to normalize embeddings before loss computation
  normalize_embeddings: false

# Checkpointing and logging
checkpoint:
  # Save checkpoint every N epochs
  save_frequency: 10

  # Keep only the best N checkpoints
  keep_best_n: 3

  # Checkpoint directory
  checkpoint_dir: "results/checkpoints"

  # Resume from checkpoint
  resume: null

# Logging configuration
logging:
  # Experiment name
  experiment_name: "hjepa_default"

  # Logging directory
  log_dir: "results/logs"

  # Log every N steps
  log_frequency: 100

  # Weights & Biases settings
  wandb:
    enabled: true
    project: "h-jepa"
    entity: null  # Your W&B username/team
    tags: ["baseline", "vit-base"]

  # TensorBoard settings
  tensorboard:
    enabled: true

# Distributed training settings
distributed:
  # Enable distributed training
  enabled: false

  # Backend (nccl, gloo)
  backend: "nccl"

  # World size (number of GPUs)
  world_size: 1

# Evaluation settings
evaluation:
  # Evaluate every N epochs
  eval_frequency: 10

  # Linear probing settings
  linear_probe:
    enabled: false
    dataset: "imagenet"
    batch_size: 256
    epochs: 90
    lr: 0.1

# Reproducibility
seed: 42

# Device settings
device: "cuda"  # cuda or cpu
